# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wwD6ec1-ifIIMRU9oOkohcX6TiQBLEM_
"""

# üìå Cell 1: Import Libraries & Load Data

# Import libraries for saving/loading models and optimization
import joblib  # For saving and loading trained models
import optuna  # For hyperparameter optimization
import time  # To measure execution time

# Import core libraries for numerical and data handling
import numpy as np  # For numerical operations
import pandas as pd  # For handling and processing datasets

# Import visualization libraries
import seaborn as sns  # For visualizing data distributions
import matplotlib.pyplot as plt  # For plotting graphs and charts

# Import machine learning classifiers
from sklearn.ensemble import RandomForestClassifier, StackingClassifier  # Random Forest and Stacking models
from sklearn.linear_model import LogisticRegression  # Logistic Regression model
from xgboost import XGBClassifier  # XGBoost Classifier
from sklearn.tree import DecisionTreeClassifier  # Decision Tree model
from sklearn.neighbors import KNeighborsClassifier  # K-Nearest Neighbors model
from sklearn.naive_bayes import MultinomialNB  # Na√Øve Bayes model for text classification

# Import model selection and validation tools
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score  # Data splitting and cross-validation

# Import performance evaluation metrics
from sklearn.metrics import (
    accuracy_score,  # Calculates accuracy
    classification_report,  # Provides precision, recall, F1-score
    precision_recall_fscore_support,  # Additional precision, recall, F1-score metrics
    confusion_matrix  # Generates confusion matrix for evaluating classification performance
)

# Import feature extraction techniques
from sklearn.feature_extraction.text import TfidfVectorizer  # Converts text into TF-IDF vectors
from sentence_transformers import SentenceTransformer  # Generates embeddings using pre-trained transformer models

# Import techniques for handling imbalanced datasets
from imblearn.over_sampling import ADASYN, SMOTE  # Oversampling methods for balancing dataset
from sklearn.utils.class_weight import compute_sample_weight  # Computes sample weights for imbalanced datasets

# Import feature selection utilities
from sklearn.feature_selection import SelectFromModel  # Selects important features from a trained model
from scipy.sparse import csr_matrix  # Handles sparse matrices efficiently (used in TF-IDF and embeddings)

# üìå Load Preprocessed Dataset
# Read the cleaned and merged dataset from a CSV file
merged_df = pd.read_csv("Multiclass_dataset/cleaned_merged_dataset.csv")

# üìå Combine Headline + Body text
# Concatenates the "Headline" and "articleBody" columns to form a single text feature
merged_df["combined_text"] = merged_df["Headline"] + " " + merged_df["articleBody"]

# üìå Manual Label Mapping (Ensures Correct Alignment)
# Define a mapping dictionary to convert categorical labels into numeric values
label_mapping = {"agree": 0, "disagree": 1, "discuss": 2, "unrelated": 3}

# Create an inverse mapping (to convert numbers back to labels if needed)
inverse_label_mapping = {v: k for k, v in label_mapping.items()}

# Apply the label mapping to convert text labels into numerical format
merged_df["Stance"] = merged_df["Stance"].map(label_mapping)

# üìå Cell 2: Feature Extraction with TF-IDF

# ‚úÖ Initialize the TF-IDF Vectorizer
tfidf = TfidfVectorizer(
    stop_words="english",  # Removes common English stopwords to improve efficiency
    max_features=10000,  # Limits the number of features to the top 10,000 most important words/phrases
    ngram_range=(1, 3)  # Considers unigrams, bigrams, and trigrams
)

# ‚úÖ Apply TF-IDF transformation to the combined text feature
X = tfidf.fit_transform(merged_df["combined_text"])  # Converts text into a sparse matrix of TF-IDF features

# ‚úÖ Save the TF-IDF Vectorizer for future use
joblib.dump(tfidf, "models/tfidf_vectorizer.pkl")
print("üíæ TF-IDF Vectorizer saved to models/tfidf_vectorizer.pkl")

# ‚úÖ Extract target labels (Stance) for classification
y = merged_df["Stance"]

# üìå Cell 3: Train-Test Split & ADASYN Oversampling

# ‚úÖ Train-Test Split using TF-IDF transformed data
X_train, X_test, y_train, y_test = train_test_split(
    X,  # Feature matrix (TF-IDF transformed text)
    y,  # Target labels (Stance classification)
    test_size=0.2,  # 20% of the data will be used for testing
    random_state=42,  # Ensures reproducibility of results
    stratify=y  # Ensures proportional distribution of stance labels in train and test sets
)

# ‚úÖ Apply ADASYN to TF-IDF transformed features
adasyn = ADASYN(
    sampling_strategy="not majority",  # Ensures only the minority classes are oversampled
    random_state=42  # Ensures reproducibility of synthetic sample generation
)

# Perform oversampling on the training set to balance class distribution
X_train_balanced, y_train_balanced = adasyn.fit_resample(X_train, y_train)

# ‚úÖ Convert X_train_balanced back to a sparse matrix
X_train_balanced = csr_matrix(X_train_balanced)  # Converts the resampled data back to a sparse format to save memory

# ‚úÖ Save the balanced dataset for future use
joblib.dump(X_train_balanced, "models/X_train_balanced.pkl")
joblib.dump(y_train_balanced, "models/y_train_balanced.pkl")
print("üíæ Balanced training dataset saved.")

# ‚úÖ Check new class distribution
print(pd.Series(y_train_balanced).value_counts())  # Prints class distribution after ADASYN

# üìå Cell 4: Class Distribution Visualization

# ‚úÖ Class Distribution Before ADASYN
plt.figure(figsize=(10, 4))  # Set figure size for better visibility
sns.countplot(x=y_train, palette="Set2")  # Plot class distribution using Seaborn countplot
plt.title("Class Distribution Before ADASYN")  # Add title for clarity
plt.show()  # Display the plot

# ‚úÖ Save Class Distribution Before ADASYN
pd.Series(y_train).value_counts().to_csv("models/class_distribution_before_adasyn.csv")
print("üíæ Class distribution before ADASYN saved.")

# ‚úÖ Class Distribution After ADASYN
plt.figure(figsize=(10, 4))  # Set figure size for better visibility
sns.countplot(x=y_train_balanced, palette="Set1")  # Plot class distribution after applying ADASYN
plt.title("Class Distribution After ADASYN")  # Add title for clarity
plt.show()  # Display the plot

# ‚úÖ Save Class Distribution After ADASYN
pd.Series(y_train_balanced).value_counts().to_csv("models/class_distribution_after_adasyn.csv")
print("üíæ Class distribution after ADASYN saved.")

# üìå Cell 5: Train Optimized Random Forest & Feature Selection

# ‚úÖ Start training timer
start_time = time.time()  # Records the start time for measuring training duration

# ‚úÖ Initialize Random Forest Classifier with optimized hyperparameters
rf_model = RandomForestClassifier(
    n_estimators=300,  # Number of trees in the forest
    max_depth=20,  # Maximum depth of each tree (limits overfitting)
    min_samples_split=10,  # Minimum number of samples required to split an internal node
    min_samples_leaf=2,  # Minimum number of samples required at a leaf node
    max_features="sqrt",  # Uses the square root of the total features per tree split
    class_weight="balanced",  # Adjusts class weights to handle imbalanced data
    random_state=42,  # Ensures reproducibility
    n_jobs=-1  # Uses all available CPU cores for faster training
)

# ‚úÖ Train the Random Forest model on the balanced dataset
rf_model.fit(X_train_balanced, y_train_balanced)

# ‚úÖ Calculate training time
rf_train_time = time.time() - start_time  # Compute total training time
print(f"‚è≥ Random Forest Training Time: {rf_train_time:.2f} seconds")  # Display training time

# ‚úÖ Feature Selection using the trained model
feature_selector = SelectFromModel(rf_model, threshold="mean")  # Select features based on importance scores
X_train_selected = feature_selector.transform(X_train_balanced)  # Apply feature selection to the training set
X_test_selected = feature_selector.transform(X_test)  # Apply feature selection to the test set

# ‚úÖ Save the trained Random Forest model and Feature Selector
joblib.dump((rf_model), "models/rf_model.pkl")
joblib.dump(feature_selector, "models/feature_selector.pkl")
print("üíæ Random Forest Model and Feature Selector saved.")

# ‚úÖ Retrain the Random Forest model with selected features
rf_model.fit(X_train_selected, y_train_balanced)

# ‚úÖ Make Predictions on the Test Set
y_pred_rf = rf_model.predict(X_test_selected)  # Predict class labels for the test set

# ‚úÖ Convert numerical predictions back to original labels
y_pred_labels_rf = pd.Series(y_pred_rf).map(inverse_label_mapping)  # Convert predicted values to labels
y_test_labels = pd.Series(y_test).map(inverse_label_mapping)  # Convert test set labels back to original format

# ‚úÖ Evaluate the Random Forest Model
print(f"‚úÖ Random Forest Test Accuracy: {accuracy_score(y_test_labels, y_pred_labels_rf):.4f}")  # Print test accuracy
print(classification_report(
    y_test_labels, y_pred_labels_rf,  # Compare true vs predicted labels
    target_names=list(label_mapping.keys()),  # Use original class labels for readability
    zero_division=0  # Avoid errors due to zero divisions
))

# ‚úÖ Generate and Display Confusion Matrix
conf_matrix = confusion_matrix(y_test_labels, y_pred_labels_rf)  # Compute confusion matrix
plt.figure(figsize=(5, 4))  # Set figure size for better visualization
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")  # Create heatmap visualization
plt.xlabel("Predicted")  # Label x-axis
plt.ylabel("Actual")  # Label y-axis
plt.title("Confusion Matrix")  # Add title
plt.show()  # Display the plot

# üìå Cell 6: XGBoost Training & Evaluation

# ‚úÖ Import necessary libraries
from sklearn.model_selection import train_test_split  # Splitting data into train/test/validation
import time  # For measuring execution time
import numpy as np  # Numerical operations
import pandas as pd  # Data handling
from xgboost import XGBClassifier  # XGBoost classifier
from scipy.sparse import csr_matrix  # Sparse matrix format to save memory
from sklearn.metrics import accuracy_score, classification_report  # Model evaluation metrics

# ‚úÖ Create a Validation Set from the Training Data
X_train_final, X_val, y_train_final, y_val = train_test_split(
    X_train_balanced,  # Training features
    y_train_balanced,  # Training labels
    test_size=0.1,  # Use 10% of the training data for validation
    random_state=42,  # Ensures reproducibility
    stratify=y_train_balanced  # Ensures proportional distribution of classes
)

# ‚úÖ Display Training and Validation Set Sizes
print(f"Training Size: {X_train_final.shape}, Validation Size: {X_val.shape}")

# ‚úÖ Convert Data to Sparse Matrix (Saves Memory)
X_train_balanced = csr_matrix(X_train_balanced)  # Convert training data to sparse matrix format
X_test = csr_matrix(X_test)  # Convert test data to sparse matrix format

# ‚úÖ Define Optimized XGBoost Model
xgb_model = XGBClassifier(
    n_estimators=250,  # ‚úÖ Reduce the number of trees to optimize training time
    learning_rate=0.09506484283779507,  # Controls step size at each boosting step
    max_depth=8,  # ‚úÖ Limits tree depth to prevent overfitting
    min_child_weight=3,  # Minimum sum of instance weight needed in a child node
    gamma=0.1777302416003415,  # Controls tree split regularization
    subsample=0.657855522236526,  # ‚úÖ Uses a fraction of data to prevent overfitting
    colsample_bytree=0.8988814540637224,  # Controls the number of features each tree considers
    eval_metric="mlogloss",  # Multi-class log loss as evaluation metric
    early_stopping_rounds=10,  # ‚úÖ Stops training if validation loss doesn't improve after 10 rounds
    tree_method="hist",  # ‚úÖ Uses histogram-based algorithm for memory efficiency
    random_state=42  # Ensures reproducibility
)

# ‚úÖ Train XGBoost with Early Stopping
start_time = time.time()  # Start training timer

xgb_model.fit(
    X_train_final, y_train_final,  # Training data
    eval_set=[(X_val, y_val)],  # Validation data for early stopping
    verbose=10  # Display progress every 10 iterations
)

xgb_train_time = time.time() - start_time  # Calculate training time
print(f"‚è≥ XGBoost Training Time: {xgb_train_time:.2f} seconds")  # Display training duration

# ‚úÖ Save the trained XGBoost model
joblib.dump((xgb_model), "models/xgb_model.pkl")
print("üíæ XGBoost Model saved to models/xgb_model.pkl")

# ‚úÖ Predict on Test Set
y_pred_xgb = xgb_model.predict(X_test)  # Generate predictions on test data

# ‚úÖ Evaluate XGBoost Model Performance
print(f"‚úÖ XGBoost Test Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}")  # Print accuracy score
print(classification_report(
    y_test, y_pred_xgb,  # Compare actual vs. predicted labels
    target_names=list(label_mapping.keys()),  # Use original class names for readability
    zero_division=0  # Prevent errors from zero division cases
))

# ‚úÖ Generate and Display Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred_xgb)  # Compute confusion matrix
plt.figure(figsize=(5, 4))  # Set figure size for better visualization
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")  # Create heatmap visualization
plt.xlabel("Predicted")  # Label x-axis
plt.ylabel("Actual")  # Label y-axis
plt.title("Confusion Matrix")  # Add title
plt.show()  # Display the plot

# üìå Cell 7: Train Decision Tree

# ‚úÖ Start timing the training process
start_time = time.time()  # Record the start time

# ‚úÖ Initialize and train the Decision Tree Classifier
dt_model = DecisionTreeClassifier(random_state=42)  # Set a fixed random state for reproducibility
dt_model.fit(X_train_balanced, y_train_balanced)  # ‚úÖ Train the model

# ‚úÖ End timing the training process
dt_train_time = time.time() - start_time  # Compute total training duration
print(f"‚è≥ Decision Tree Training Time: {dt_train_time:.2f} seconds")  # Display training duration

# ‚úÖ Save the trained Decision Tree model
joblib.dump((dt_model), "models/dt_model.pkl")
print("üíæ Decision Tree Model saved to models/dt_model.pkl")

# ‚úÖ Predict on the test dataset (Note: The test set was not balanced)
y_pred = dt_model.predict(X_test)  # ‚úÖ Use the trained model for prediction

# ‚úÖ Compute Accuracy Score
accuracy = accuracy_score(y_test, y_pred)

# ‚úÖ Compute Precision, Recall, F1-score, and Support (Per Class)
precision, recall, f1_score, support = precision_recall_fscore_support(
    y_test, y_pred, zero_division=0
)

# ‚úÖ Generate a Classification Report
class_report = classification_report(y_test, y_pred, target_names=list(label_mapping.keys()), zero_division=0)

# ‚úÖ Compute Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# ‚úÖ Print Evaluation Metrics
print("\n========== MODEL EVALUATION ==========")
print(f"Training Time: {dt_train_time:.4f} seconds\n")
print(f"Test Accuracy: {accuracy:.4f}\n")
print("\n=========== CLASSIFICATION REPORT ===========\n")
print(class_report)

# ‚úÖ Plot the Confusion Matrix
print("\n=========== CONFUSION MATRIX ===========\n")
plt.figure(figsize=(8, 6))
sns.heatmap(
    cm, annot=True, fmt='d', cmap='Blues', cbar=False,
    xticklabels=inverse_label_mapping.values(),
    yticklabels=inverse_label_mapping.values()
)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# üìå Cell 8: Train K-Nearest Neighbors (KNN) Model

# ‚úÖ Initialize KNN model with specified hyperparameters
knn = KNeighborsClassifier(
    n_neighbors=1,  # ‚úÖ Uses 1 nearest neighbor for classification
    algorithm="brute",  # ‚úÖ Uses brute-force search to find nearest neighbors
    metric="euclidean",  # ‚úÖ Computes distances using Euclidean distance
    weights="uniform"  # ‚úÖ Assigns equal weight to all neighbors
)

# ‚úÖ Start timer to measure training time
start_train_time = time.time()  # Records the start time

# ‚úÖ Train the KNN model on the balanced training set
knn.fit(X_train_balanced, y_train_balanced)

# ‚úÖ Compute training time
knn_train_time = time.time() - start_train_time  # Compute time taken for training
print(f"‚è≥ KNN Training Time: {knn_train_time:.4f} seconds")  # Display training time

# ‚úÖ Save the trained KNN model with training time
joblib.dump((knn), "models/knn_model.pkl")
print("üíæ KNN Model saved to models/knn_model.pkl")

# ‚úÖ Start timer to measure prediction time
start_pred_time = time.time()  # Records the start time

# ‚úÖ Predict class labels for the test set
y_pred = knn.predict(X_test)

# ‚úÖ Compute prediction time
prediction_time = time.time() - start_pred_time  # Compute time taken for predictions
print(f"‚è≥ KNN Prediction Time: {prediction_time:.4f} seconds")  # Display prediction time

# ‚úÖ Evaluate Model Performance
accuracy = accuracy_score(y_test, y_pred)  # Compute accuracy score
print(f"‚úÖ Test Accuracy: {accuracy:.4f}")  # Print accuracy

# ‚úÖ Generate a Classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=list(label_mapping.keys()), zero_division=0))  # Print precision, recall, F1-score per class

# ‚úÖ Compute and Plot the Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)  # Compute confusion matrix

# ‚úÖ Visualize the Confusion Matrix using Seaborn
plt.figure(figsize=(8, 6))  # Set figure size
sns.heatmap(
    conf_matrix, annot=True, fmt="d", cmap="Blues",  # Create a heatmap for confusion matrix
    xticklabels=inverse_label_mapping.values(),  # Set X-axis labels
    yticklabels=inverse_label_mapping.values()   # Set Y-axis labels
)
plt.xlabel("Predicted")  # Label X-axis
plt.ylabel("Actual")  # Label Y-axis
plt.title("Confusion Matrix - KNN")  # Add title to the plot
plt.show()  # Display the plot

# üìå Cell 9: Train Optimized Na√Øve Bayes Model

# ‚úÖ Start timing the training process
nb_train_time = time.time()  # Records the start time

# ‚úÖ Initialize the Multinomial Na√Øve Bayes model with specified hyperparameters
nb_model = MultinomialNB(
    alpha=1.0,  # ‚úÖ Smoothing parameter (Laplace smoothing)
    fit_prior=True,  # ‚úÖ Learn class prior probabilities from data
    class_prior=None  # ‚úÖ Class priors are not manually specified, letting the model determine them
)

# ‚úÖ Train the Na√Øve Bayes model on the balanced training set
nb_model.fit(X_train_balanced, y_train_balanced)

# ‚úÖ Save the trained Na√Øve Bayes model
joblib.dump((nb_model), "models/nb_model.pkl")
print("üíæ Na√Øve Bayes Model saved to models/nb_model.pkl")

# ‚úÖ Calculate training time
nb_train_time = time.time() - start_time  # Compute total training duration
print(f"‚åõ Na√Øve Bayes Training Time: {nb_train_time:.2f} seconds\n")  # Display training duration

# ‚úÖ Make Predictions on the Test Set
y_pred = nb_model.predict(X_test)  # Generate predictions for the test set

# ‚úÖ Evaluate Model Performance
accuracy = accuracy_score(y_test, y_pred)  # Compute accuracy score
print(f"‚úÖ Na√Øve Bayes Test Accuracy: {accuracy:.4f}\n")  # Display test accuracy

# ‚úÖ Generate a Classification Report
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=list(label_mapping.keys()), zero_division=0))  # Print precision, recall, F1-score

# ‚úÖ Compute and Plot the Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)  # Compute confusion matrix

# ‚úÖ Visualize the Confusion Matrix using Seaborn
plt.figure(figsize=(5, 4))  # Set figure size for better visualization
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")  # Create a heatmap for confusion matrix
plt.xlabel("Predicted")  # Label X-axis
plt.ylabel("Actual")  # Label Y-axis
plt.title("Confusion Matrix - Na√Øve Bayes")  # Add title to the plot
plt.show()  # Display the plot

# üìå Cell 10: Stacking Classifier with XGBoost, Random Forest, and Logistic Regression

# ‚úÖ Import necessary libraries
import time  # For measuring execution time
import numpy as np  # Numerical operations
import pandas as pd  # Data handling
import seaborn as sns  # Data visualization
import matplotlib.pyplot as plt  # Plotting graphs
from sklearn.ensemble import RandomForestClassifier, StackingClassifier  # Random Forest & Stacking
from sklearn.linear_model import LogisticRegression  # Logistic Regression (meta-classifier)
from xgboost import XGBClassifier  # XGBoost Classifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Evaluation metrics

# ‚úÖ Step 1: Define XGBoost Model (Without Early Stopping for Stacking)
xgb_stacking_model = XGBClassifier(
    n_estimators=150,  # Number of boosting rounds
    learning_rate=0.09506484283779507,  # Step size shrinkage
    max_depth=8,  # Maximum tree depth
    min_child_weight=3,  # Minimum sum of instance weight in a child
    gamma=0.1777302416003415,  # Regularization parameter to control splits
    subsample=0.657855522236526,  # Fraction of samples used for training trees
    colsample_bytree=0.8988814540637224,  # Fraction of features used per tree
    eval_metric="mlogloss",  # Multi-class log loss as evaluation metric
    tree_method="hist",  # Optimized histogram-based algorithm for efficiency
    random_state=42  # Ensures reproducibility
)

# ‚úÖ Step 2: Train XGBoost Separately for Debugging
print("üîç Debug: Training XGBoost Separately to Verify Functionality...")
start_xgb = time.time()  # Start timing
xgb_stacking_model.fit(X_train_balanced, y_train_balanced)  # Train the model
xgb_train_time = time.time() - start_xgb  # Calculate training time
xgb_preds = xgb_stacking_model.predict(X_test)  # Generate predictions
print(f"‚úÖ XGBoost Standalone Accuracy: {accuracy_score(y_test, xgb_preds):.4f}")  # Display accuracy
print(f"‚è≥ XGBoost Training Time: {xgb_train_time:.2f} seconds\n")  # Display training time

# ‚úÖ Step 3: Train Random Forest Separately for Debugging
rf_model = RandomForestClassifier(
    n_estimators=200,  # Number of trees in the forest
    max_depth=20,  # Maximum tree depth to prevent overfitting
    min_samples_split=10,  # Minimum samples required to split a node
    min_samples_leaf=2,  # Minimum samples per leaf node
    max_features="sqrt",  # Number of features per split (square root of total)
    class_weight="balanced",  # Adjusts class weights to handle imbalance
    random_state=42,  # Ensures reproducibility
    n_jobs=-1  # Uses all available CPU cores for faster training
)
print("üîç Debug: Training Random Forest Separately to Verify Functionality...")
start_rf = time.time()  # Start timing
rf_model.fit(X_train_balanced, y_train_balanced)  # Train the model
rf_train_time = time.time() - start_rf  # Calculate training time
rf_preds = rf_model.predict(X_test)  # Generate predictions
print(f"‚úÖ Random Forest Standalone Accuracy: {accuracy_score(y_test, rf_preds):.4f}")  # Display accuracy
print(f"‚è≥ Random Forest Training Time: {rf_train_time:.2f} seconds\n")  # Display training time

# ‚úÖ Step 4: Define Stacking Classifier (Combining XGBoost & Random Forest)
stacked_model = StackingClassifier(
    estimators=[('rf', rf_model), ('xgb', xgb_stacking_model)],  # Base learners
    final_estimator=LogisticRegression()  # Meta-classifier to make final decision
)

# ‚úÖ Step 5: Train Stacking Model
print("\nüöÄ Training Stacking Model...")
start_stacking = time.time()  # Start timing
stacked_model.fit(X_train_balanced, y_train_balanced)  # Train the stacked model
stacking_train_time = time.time() - start_stacking  # Calculate training time
print(f"‚úÖ Stacking Model Training Completed in {stacking_train_time:.2f} seconds")  # Display training time

# ‚úÖ Save the trained Stacking Classifier model
joblib.dump((stacked_model), "models/stacking_model.pkl")
print("üíæ Stacking Classifier Model saved to models/stacking_model.pkl")

# ‚úÖ Step 6: Generate Predictions using Stacking Model
print("üîç Generating Predictions...")
start_prediction = time.time()  # Start timing
stacked_preds = stacked_model.predict(X_test)  # Predict on test data
prediction_time = time.time() - start_prediction  # Calculate prediction time

# ‚úÖ Step 7: Debug: Check if Predictions Exist
print(f"‚úÖ Sample Predictions: {stacked_preds[:10]}")  # Display first 10 predictions

# ‚úÖ Step 8: Evaluate Stacking Model
print(f"‚úÖ Stacked Model Accuracy: {accuracy_score(y_test, stacked_preds):.4f}")  # Display accuracy
print(classification_report(y_test, stacked_preds, target_names=list(label_mapping.keys()), zero_division=0))  # Print classification report

# ‚úÖ Step 9: Generate and Plot Confusion Matrix
conf_matrix = confusion_matrix(y_test, stacked_preds)  # Compute confusion matrix
plt.figure(figsize=(5, 4))  # Set figure size
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")  # Create heatmap visualization
plt.xlabel("Predicted")  # Label x-axis
plt.ylabel("Actual")  # Label y-axis
plt.title("Confusion Matrix - Stacking Classifier")  # Add title
plt.show()  # Display the plot

# ‚úÖ Step 10: Compute Total Execution Time
total_time = xgb_train_time + rf_train_time + stacking_train_time + prediction_time  # Compute total time
print("\n‚è≥ Training Time Summary:")
print(f"üîπ XGBoost Training Time: {xgb_train_time:.2f} seconds")
print(f"üîπ Random Forest Training Time: {rf_train_time:.2f} seconds")
print(f"üîπ Stacking Model Training Time: {stacking_train_time:.2f} seconds")
print(f"üîπ Prediction Time: {prediction_time:.2f} seconds")
print(f"üöÄ Total Time for Training & Prediction: {total_time:.2f} seconds")  # Display total execution time

# üìå Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import time
import os
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_recall_fscore_support
)

# ‚úÖ Ensure the models directory exists
os.makedirs("models", exist_ok=True)

# üìå Dictionary to store model evaluation results
model_results = {}

# üìå Helper function to evaluate models and store results dynamically
def evaluate_model(model_name, model, X_test, y_test, retrain=False, X_train=None, y_train=None):
    """
    Evaluates a trained model, dynamically measures training time if retraining,
    stores results, and displays classification report & confusion matrix.
    """

    # ‚úÖ Train the model and measure training time if retraining is enabled
    if retrain and X_train is not None:
        start_time = time.time()
        model.fit(X_train, y_train)  # Train the model
        train_time = time.time() - start_time  # Compute training duration
    else:
        train_time = np.nan  # No retraining; mark training time as NaN

    # ‚úÖ Start prediction timer
    start_pred_time = time.time()
    y_pred = model.predict(X_test)  # Generate predictions
    pred_time = time.time() - start_pred_time  # Compute prediction time

    # ‚úÖ Compute evaluation metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average="weighted", zero_division=0)

    # ‚úÖ Store results in dictionary
    model_results[model_name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "Training Time (s)": train_time,  # Timing is not working properly, use the timings for the individual models
        "Prediction Time (s)": pred_time
    }

    # ‚úÖ Print classification report
    print(f"\nüîπ {model_name} Model Performance")
    target_names=list(label_mapping.keys()),  # Use original class names for readability
    print(f"‚úÖ Accuracy: {accuracy:.4f}")
    print(f"‚úÖ Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}")
    print(classification_report(y_test, y_pred, zero_division=0))

    # ‚úÖ Compute and Plot the Confusion Matrix
    conf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Confusion Matrix - {model_name}")
    plt.show()


# üìå Load Saved Models (without Training Time)
rf_model = joblib.load("models/rf_model.pkl")
dt_model = joblib.load("models/dt_model.pkl")
knn_model = joblib.load("models/knn_model.pkl")
nb_model = joblib.load("models/nb_model.pkl")
xgb_model = joblib.load("models/xgb_model.pkl")
stacked_model = joblib.load("models/stacking_model.pkl")

# ‚úÖ Evaluate Models (Dynamic Training Time Measurement)
evaluate_model("Random Forest", rf_model, X_test, y_test, retrain=False)
evaluate_model("Decision Tree", dt_model, X_test, y_test, retrain=False)
evaluate_model("KNN", knn_model, X_test, y_test, retrain=False)
evaluate_model("Na√Øve Bayes", nb_model, X_test, y_test, retrain=False)
xgb_model.set_params(early_stopping_rounds=True)
evaluate_model("XGBoost", xgb_model, X_test, y_test, retrain=False)
evaluate_model("Stacking Model", stacked_model, X_test, y_test, retrain=False)


# üìå Convert results dictionary to DataFrame
results_df = pd.DataFrame(model_results).T  # Transpose for readability

print("\nüîç Model Performance Comparison:")
print(results_df)  # Display the evaluation results

# ‚úÖ Save evaluation results (excluding model timings)
joblib.dump(results_df, "models/model_comparison.pkl")
print("üíæ Model evaluation results saved to models/model_comparison.pkl")

# üìå Plot Accuracy Comparison
plt.figure(figsize=(8, 5))
sns.barplot(data=results_df, x=results_df.index, y="Accuracy")
plt.xticks(rotation=45)
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy Score")
plt.show()

# ‚úÖ Import necessary libraries
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.base import clone  # ‚úÖ Ensures fresh instances of models
import numpy as np
import time
import joblib  # Load trained models

# ‚úÖ Define Optimized 3-Fold Cross-Validation Strategy (Faster Execution)
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

# üìå Function to Perform Cross-Validation with Execution Timing
def perform_cross_validation(model, model_name, X_train, y_train):
    """
    Runs 3-fold cross-validation for the given model, tracks execution time,
    and prints accuracy with standard deviation.
    """
    print(f"\nüöÄ Running Cross-Validation for {model_name}...")  # Notify start of validation

    start_time = time.time()  # Start timer for execution time tracking
    scores = cross_val_score(clone(model), X_train, y_train, cv=cv, scoring="accuracy", n_jobs=-1)  # Run CV in parallel
    exec_time = time.time() - start_time  # Compute total execution time

    # ‚úÖ Print Cross-Validation Results
    print(f"‚úÖ {model_name} Cross-Validation Accuracy: {np.mean(scores):.4f} ¬± {np.std(scores):.4f}")
    print(f"‚è≥ {model_name} Cross-Validation Time: {exec_time:.2f} seconds")  # Display execution time

# üìå Load Saved Models for Cross-Validation
rf_model = joblib.load("models/rf_model.pkl")
dt_model = joblib.load("models/dt_model.pkl")
knn_model = joblib.load("models/knn_model.pkl")
nb_model = joblib.load("models/nb_model.pkl")
xgb_model = joblib.load("models/xgb_model.pkl")
stacked_model = joblib.load("models/stacking_model.pkl")

# ‚úÖ Fix XGBoost: Disable Early Stopping
xgb_model.set_params(early_stopping_rounds=None, n_jobs=-1)  # ‚úÖ Runs XGBoost in parallel

# ‚úÖ Run Cross-Validation for Each Model
perform_cross_validation(dt_model, "Decision Tree", X_train_balanced, y_train_balanced)
perform_cross_validation(nb_model, "Na√Øve Bayes", X_train_balanced, y_train_balanced)
perform_cross_validation(rf_model, "Random Forest", X_train_balanced, y_train_balanced)
perform_cross_validation(knn_model, "KNN", X_train_balanced, y_train_balanced)
perform_cross_validation(xgb_model, "XGBoost", X_train_balanced, y_train_balanced)

# ‚úÖ Fix: Clone Stacking Model for Each Fold
print("\nüöÄ Running Cross-Validation for Stacking Model...")
start_time = time.time()
stacked_cv_scores = cross_val_score(clone(stacked_model), X_train_balanced, y_train_balanced, cv=cv, scoring="accuracy", n_jobs=-1)
exec_time = time.time() - start_time  # Track execution time

print(f"‚úÖ Stacking Model Cross-Validation Accuracy: {np.mean(stacked_cv_scores):.4f} ¬± {np.std(stacked_cv_scores):.4f}")
print(f"‚è≥ Stacking Model Cross-Validation Time: {exec_time:.2f} seconds")
